{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아이온 이탈 유저 예측\n",
    "> 클래스를 분류하기 보다는 실제 회귀식을 구하는 것이 목적이나, 일반 분류기로는 예측하기는 어렵기 때문에 클래스 구분으로 일단 한 번 더 시도해보기로 함\n",
    "\n",
    "### 1. 클래스 맵핑\n",
    "> 0 - 5 사이의 값은 0, 6 ~ 15 사이 값은 5, ... , 55+ 이상은 55 으로 클래스 맵핑\n",
    "> 구글 닥스에 업로드 후 vslookup 통하여 관련 전처리 수행하고 csv 로 다운로드\n",
    "\n",
    "### 2. 추가 특질\n",
    "> id, week 정보로 sort 한 이후에 접속 횟수를 특질로 추가\n",
    "> 맥 로컬에서 sort 후 저장\n",
    "\n",
    "### 3.  선형 회귀 기울기를 4주차 간 수행하여 특질로 변경\n",
    "> 정렬된 데이터를 기준으로 세션처리를 통해서 특질(최대접속주차, 최대 4주간의 기울기를 특질 별로 생성)\n",
    "> linear regression 통해서 각 지표의 4주 간의 X = { 1, 2, 3, 4 } Y = { y1, y2, y3, y4 } 기울기를 특질로 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -7.14005906e-27  -3.45134058e-10   1.23385426e-08   4.89820108e-02\n",
      "  -5.46462259e-09  -3.90116530e-07   2.01328201e-10   9.98799661e-01\n",
      "   0.00000000e+00   3.65266878e-09   2.99211096e-06  -8.39826208e-09\n",
      "  -3.80337732e-07]\n"
     ]
    }
   ],
   "source": [
    "# -- 세션처리 통해서 actor_account_id 당 4주의 데이터를 묶는 작업  -- 25개 필드\n",
    "#!/usr/bin/env python\n",
    "# -*- coding:utf -*-\n",
    "import sys, csv\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 파일을 읽어서 Dictionary 형태의 List 로 반환하는 함수\n",
    "def dictionize(filename):\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        data = [r for r in reader]\n",
    "    return data\n",
    "\n",
    "# 파일을 읽어서 List of List 형태로 반환하는 함수\n",
    "def listinize(filename):\n",
    "    with open(filename) as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) # skip header\n",
    "        data = [r for r in reader]\n",
    "    return data\n",
    "\n",
    "\"\"\" \n",
    "-- 사전 정의된 (23개)\n",
    "actor_account_id : 계정 ID\n",
    "combine_cnt : 제작 횟수\n",
    "dice_cnt : 주사위 횟수\n",
    "enter_dd_cnt : 주간 접속 일자 수\n",
    "exp_get : 경험치 획득량\n",
    "fortress_cnt : 요새전 보상 횟수\n",
    "get_ap :AP 획득량\n",
    "get_gp : GP 획득량\n",
    "glide_cnt : 활강 횟수\n",
    "harvest_cnt : 채집 횟수\n",
    "inc_kina_sum :키나 획득량 (개인간 거래 포함)\n",
    "indun_cnt : 인스턴스 던전 입장 횟수\n",
    "kina_sys_inc : 개인간 거래를 제외한 키나 증가량 (e.g. 사냥, 퀘스트 등으로 획득한 키나)\n",
    "kina_sys_dec : 개인간 거래를 제외한 키나 감소량 (e.g. NPC 구매, 텔레포트 등으로 사용한 키나)\n",
    "npc_sell_kinasum : 상점 판매로 획득한 키나량\n",
    "pay_amt_total : 한 주간 구매한 금액 (주별로 표준화 되어있음)\n",
    "pvp_cnt : PvP 횟수\n",
    "playtime_ss : 플레이타임(초)\n",
    "pve_cnt : NPC 킬 횟수\n",
    "quest_cnt : 퀘스트 완료 횟수\n",
    "teleport_cnt : 텔레포트 횟수\n",
    "use_scroll_cnt : 주문서 사용 횟수\n",
    "week : 플레이한 주 차 ( 계정별 최대 4주 )\n",
    "\n",
    "-- 추가 지표 증가량 lm.coef_ (13개))\n",
    "\n",
    "x_combine_cnt\n",
    "x_enter_dd_cnt\n",
    "x_exp_get\n",
    "x_fortress_cnt\n",
    "x_get_ap\n",
    "x_get_gp\n",
    "x_harvest_cnt\n",
    "x_inc_kina_sum\n",
    "x_playtime_ss\n",
    "x_pve_cnt\n",
    "x_pvp_cnt\n",
    "x_quest_cnt\n",
    "x_use_scroll_cnt\n",
    "\n",
    "-- 정답 label (2개)\n",
    "z_survival_time : 유지 일자 \n",
    "z_survival : 유지 그룹 라벨 (c_0, c_5, c_15, c_25, c_35, c_45, c_55) 총 6개 그룹으로 정의\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 입력받은 튜플들의 각 값들의  주어진 킷값들에 대해서 평균치를 저장하여 하나의 dict 로 반환\n",
    "#\n",
    "# arguements sessions as list[dict]\n",
    "# returns dict\n",
    "#\n",
    "def average_sessions(sessions, keys_sessions):\n",
    "    average = sessions[0]\n",
    "    average[\"week\"] = 0\n",
    "    average[\"y_survival\"] = average.pop(\"survival\")\n",
    "    average[\"y_survival_time\"] = average.pop(\"survival_time\")\n",
    "    \n",
    "    num_of_sessions = len(sessions)\n",
    "    if num_of_sessions == 1:\n",
    "        average[\"week\"] = 1\n",
    "        return average\n",
    "    \n",
    "    for session in sessions:\n",
    "        for key in keys_sessions:\n",
    "            value = session.get(key)\n",
    "            if key == \"actor_account_id\":\n",
    "                average[key] = value\n",
    "            elif key == \"week\":\n",
    "                average[key] = int(average.get(\"week\", 0)) + 1\n",
    "            else:\n",
    "                average[key] = float(average.get(key, 0.0)) + float(value)\n",
    "                \n",
    "    for key in keys_sessions:\n",
    "        if key != \"actor_account_id\" and key != \"week\":\n",
    "            average[key] = float(average.get(key)) / num_of_sessions\n",
    "            \n",
    "    return average\n",
    "\n",
    "# 입력 받은 킷값에 대하여 주어진 튜플들의 선형 회귀 직선의 기울기를 추가하여 x_${key} 값으로 dict 반환\n",
    "# 단 튜플 수가 1개이면 모든 값은 0.0으로 반환\n",
    "def extract_coef(sessions, keys):\n",
    "    coef = {}\n",
    "    num_of_sessions = len(sessions)\n",
    "    # 튜플 수가 1개인 경우만 먼저 적용\n",
    "    if len(sessions) == 1:\n",
    "        coef = { \"x_\" + key:0.0 for key in keys }\n",
    "    else:\n",
    "        X = np.asarray(list(range(num_of_sessions)), dtype=np.float)\n",
    "        X_train = X.reshape(num_of_sessions, 1)\n",
    "        regressor = LinearRegression()\n",
    "        for key in keys:\n",
    "            Y = np.asarray([ sessions[x][key] for x in range(num_of_sessions) ], dtype=np.float)\n",
    "#             Y = preprocessing.normalize(Y, norm='l2') # normalize 하면 수치가 너무 작아져서 coef 값이 변별력이 떨어짐.\n",
    "            y_train = Y.reshape(num_of_sessions, 1)\n",
    "            regressor.fit(X_train, y_train)\n",
    "            coef[\"x_\" + key] = regressor.coef_[0][0]# 기울기는 coef 이고, 절편이 coef 이다.!\n",
    "    coef_array = np.asarray(list(coef.values()), dtype=np.float) # dict.values => list => array 후 normalize\n",
    "    coef_norm = coef_array / np.linalg.norm(coef_array)\n",
    "    return coef_norm\n",
    "\n",
    "keys_sessions = [ \"actor_account_id\", \"combine_cnt\", \"dice_cnt\", \"enter_dd_cnt\", \"exp_get\"\n",
    "                 , \"fortress_cnt\" , \"get_ap\", \"get_gp\", \"glide_cnt\", \"harvest_cnt\"\n",
    "                 , \"inc_kina_sum\" ,  \"indun_cnt\", \"kina_sys_inc\", \"kina_sys_dec\", \"npc_sell_kinasum\"\n",
    "                 , \"pay_amt_total\" , \"pvp_cnt\", \"playtime_ss\", \"pve_cnt\", \"quest_cnt\"\n",
    "                 , \"teleport_cnt\" , \"use_scroll_cnt\", \"week\" ] # 23개\n",
    "keys_coef = [ \"combine_cnt\", \"enter_dd_cnt\", \"exp_get\", \"fortress_cnt\", \"get_ap\"\n",
    "                   , \"get_gp\", \"harvest_cnt\", \"inc_kina_sum\", \"playtime_ss\", \"pve_cnt\"\n",
    "                   , \"pvp_cnt\", \"quest_cnt\", \"use_scroll_cnt\" ] # 13개\n",
    "keys_labels = [ \"survival\", \"survival_time\" ] # 2개\n",
    "\n",
    "# 최대 4개의 로그를 받아서 최종 출력 대상 튜플을 반환하는 함수\n",
    "# 적어도 2개 이상의 튜플이 있어야 증감을 측정할 수 있으므로 튜플이 하나이면 모든 값들을 그대로 쓰고, 증감 수치는 0으로 저장\n",
    "# 일반 필드의 값들은 평균치를 취하여 값으로 저장하도록 한다.\n",
    "# 기존의 값들은 그대로 사용하는 것이 좋을 것 같고 증감에 유의미한 필드에 대해서만 선정해서 필드를 추가하도록 수정\n",
    "def sessionize(sessions):\n",
    "    x_session = average_sessions(sessions, keys_sessions)\n",
    "    x_coef = extract_coef(sessions, keys_coef)\n",
    "    x_session.update(x_coef)\n",
    "    return x_session\n",
    "\n",
    "# 세션 목록을 디버깅 하기 위한 함수\n",
    "def debug_sessions(sessions):\n",
    "    for session in sessions:\n",
    "        for key in sorted(session.keys()):\n",
    "            value = session.get(key)\n",
    "            print(key, value)\n",
    "        print(session.get(\"actor_account_id\"), session.get(\"week\"), session.get(\"y_survival_time\"))\n",
    "        print(session)\n",
    "        \n",
    "def create_headers():\n",
    "    headers = keys_sessions + [ \"x_\" + key for key in keys_coef ] + [ \"y_\" + key for key in keys_labels ]\n",
    "    return headers\n",
    "\n",
    "# 생성된 dict 객체를 파일로 저장하는 함수\n",
    "def store_sessions(filename, sessions, headers):\n",
    "    with open(filename, 'w+') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(headers)\n",
    "        for session in sessions:\n",
    "           # writer.writerow([ [value] for key, value in sorted(session.items()) ])\n",
    "           writer.writerow([ value for key, value in sorted(session.items()) ])\n",
    "            \n",
    "            \n",
    "def main(source_data, target_data):\n",
    "    # 파일을 읽어서 동일한 actor_account_id 값을 하나로 묶고, actor 당, 출석일수, 행동의 coef 값을 반환하는 함수\n",
    "    items = dictionize(source_data)\n",
    "    prev_id = None\n",
    "    curr_id = None\n",
    "    sessions = []\n",
    "    x_sessions = []\n",
    "    for item in items:\n",
    "        curr_id = item.get(\"actor_account_id\")\n",
    "        if prev_id != None and prev_id != curr_id:\n",
    "            x_session = sessionize(sessions)\n",
    "            x_sessions.append(x_session)\n",
    "            sessions.clear()\n",
    "        prev_id = curr_id\n",
    "        sessions.append(item)\n",
    "\n",
    "    if len(sessions) > 0:\n",
    "        x_session = sessionize(sessions)\n",
    "        x_sessions.append(x_session)\n",
    "\n",
    "    headers = create_headers()\n",
    "    store_sessions(target_data, x_sessions, headers)\n",
    "    \n",
    "\n",
    "\n",
    "def test_extract_coef(source):\n",
    "    items = dictionize(source)\n",
    "    sessions = []\n",
    "    x_sessions = []\n",
    "    x_coef = extract_coef(items, keys_coef)\n",
    "    print(x_coef)\n",
    "    \n",
    "\n",
    "__TEST__ = False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    source=\"data/data_label_sorted.csv\"\n",
    "    target=\"data/data_label_output.csv\"\n",
    "    \n",
    "    if __TEST__:\n",
    "        source=\"./source.csv\"\n",
    "        target=\"./target.csv\"\n",
    "        test_extract_coef(source)\n",
    "    else:\n",
    "        main(source, target)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6.20633538e-18]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "X = np.asarray([1, 2, 3, 4], dtype=np.float)\n",
    "X_train = X.reshape(4,1)\n",
    "Y = np.asarray([2,3,3,2], dtype=np.float)\n",
    "Y = preprocessing.normalize(Y, norm='l2')\n",
    "y_train = Y.reshape(4,1)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "# print(Y, y_train)\n",
    "# print(regressor.intercept_)\n",
    "print(regressor.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(1000)*10\n",
    "print(x.shape)\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "pvp_cnt\n",
      "x_combine_cnt 0.0\n",
      "x_enter_dd_cnt 0.0\n",
      "x_exp_get 0.0\n",
      "x_fortress_cnt 0.0\n",
      "x_get_ap 0.0\n",
      "x_get_gp 0.0\n",
      "x_harvest_cnt 0.0\n",
      "x_inc_kina_sum 0.0\n",
      "x_playtime_ss 0.0\n",
      "x_pve_cnt 0.0\n",
      "x_pvp_cnt 0.0\n",
      "x_quest_cnt 0.0\n",
      "x_use_scroll_cnt 0.0\n"
     ]
    }
   ],
   "source": [
    "keys_intercepts = [ \"exp_get\", \"pvp_cnt\", \"quest_cnt\", \"inc_kina_sum\", \"enter_dd_cnt\", \"playtime_ss\", \"pve_cnt\", \"get_ap\", \"get_gp\",  \"fortress_cnt\", \"harvest_cnt\", \"combine_cnt\", \"use_scroll_cnt\" ]\n",
    "print(len(keys_intercepts))\n",
    "print(keys_intercepts[1])\n",
    "data = { \"x_\" + key:0.0 for key in keys_intercepts }\n",
    "for key in sorted(data.keys()):\n",
    "    value = data.get(key)\n",
    "    print(key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 2.]\n",
      " [ 3.]]\n",
      "[[ 10.]\n",
      " [ 20.]\n",
      " [ 30.]]\n",
      "[[ 100.]\n",
      " [  30.]\n",
      " [ 300.]]\n"
     ]
    }
   ],
   "source": [
    "names = [\"a\", \"b\", \"c\"]\n",
    "y = [ {\"a\":\"1\", \"b\":\"10\", \"c\":\"100\"}, {\"a\":\"2\", \"b\":\"20\", \"c\":\"30\"}, {\"a\":\"3\", \"b\":\"30\", \"c\":\"300\"} ]\n",
    "num_of_y = len(y)\n",
    "import numpy as np\n",
    "for name in names:\n",
    "    Y = np.asarray([ y[i][name] for i in range(num_of_y) ], dtype=np.float)\n",
    "    Y = Y.reshape(num_of_y, 1)\n",
    "    print(Y)\n",
    "\n",
    "# Y = np.asarray([1.389234,8.389,19.233,0.8], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['20000'], ['10'], ['100']]\n",
      "[['2'], ['20'], ['30']]\n",
      "[['3'], ['30'], ['300']]\n"
     ]
    }
   ],
   "source": [
    "sessions = [ {\"x\":\"20000\", \"y\":\"10\", \"z\":\"100\"}, {\"a\":\"2\", \"b\":\"20\", \"c\":\"30\"}, {\"a\":\"3\", \"b\":\"30\", \"c\":\"300\"} ]\n",
    "for session in sessions:\n",
    "    print([[value] for key, value in sorted(session.items())])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tf35]",
   "language": "python",
   "name": "Python [tf35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
