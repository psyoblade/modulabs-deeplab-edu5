# 4장. 신경망 학습

## 4.1. 데이터를 통해 학습한다

### 배치용 교차 엔트로피 오차 구현하기
* [http://laonple.blog.me/220554852626](테스트)

### 엔트로피란?
* [http://blog.acronym.co.kr/433](정보이론에서 엔트로핀라..)
* 어떤 확률변수의 불확실을 측정하는 수, Claude Shannon 은 정보량이라 표현했다
* entropy = -1 * Sigma { p(x) * log2(p(x)) } 와 같이 곱의 합으로 계산
* 확률은 0~1 사이의 값이며 log 취한 값은 음수로 나와서 결과값은 항상 양수가 나온다
* 4x4 크기의 트럼프 카드를 놓아두었고, 임의의 질문을 통해 알아맞힐 수 있는 회수는 4회인데 2^4=16 이라고 표현된다.
* 이는 4번의 질문으로 불확실성을 해결하였으므로, 엔트로피는 4라고 말할 수 있다
* 밑수가 2인 로그의 경우 2진수 표현에서 bit는 각 자리수를 말하므로 숫자 16을 표현할 수 있는 최소 자릿수.
* "어떤 랜덤변수가 8가지의 상태로 동일한 확률로 발생한다고 할 때에, 엔트로피는 무엇이고, 어떤 의미를 가지는가?"
    * 2 ^ 3 = 8 이며, 이는 3번으로 불확실성을 없앨 수 있고, 3bit로 모든 수를 표현할 수 있다
* "그러면, 8개의 확률변수가 등장할 각 각의 확률이 다른경우는 어떠하고, 어떤 경우에 더 높아지고, 낮아지는가?"
    * 균등한 경우보다 불균등한 경우가 더 엔트로피 값이 작고, 이는 더 쉽게 맞출 수 있고, 불확실성이 낮아졌다고 말할 수 있다

### 교차 엔트로피란?
* 위에서 엔트로피란, 불확실성이고 균등한 경우에 가장 높다라고 말했는데, 
* 어떤 확률분포의 무작위성(randomness)를 말하며, 확률분포를 갖는 랜덤변수 X를 표현하기 위한 최소 비트수
    * cross-entropy = -1\*Sigma{p(x)\*log2(m(x))} 이며  두 가지 확률분포가 동일한 경우에 최소값이 나온다

### 크로스 엔트로피? 어떻게 응용이 가능한가?
* 두 확률분포가 얼마나 가깝거나 혹은 먼지를 나타내는 값이다.
* cost function 과 같이 기대값(확률변수)와 실제 연산값의 차이가 클 수록 큰 값이 나오고 항상 양수로 나온다
* 좀 더 자세한 사항은 [http://iew3.technion.ac.il/CE/](Cross-Entropy) 에서 확인이 가능하다


## 4.2 손실함수 

### 4.2.5 왜 손실 함수를 설정하는가?
* 신경망 학습에서는 최적의 매개변수(가중치 w와 편향 b)를 탐색할 때 손실 함수의 값을 가능한 한 작게 하는 매개변수 값을 찾습니다.
    * 즉, 미분 값을 (기울기) 계산하고, 해당 미분값을 단서로 매개변수를 서서히 갱신하는 것
    * '가중치 매개변수의 값을 아주 조금 변화 시켰을 때, 손실 함수가 어떻게 변하나'라는 의미
    * 미분 값이 양수(+)이면 음의 방향으로 음수(-)이면 양의 방향으로 0이면 수렴했다고 보고 멈춘다
* 신경망을 학습할 때 정확도를 지표로 삼아서는 안 된다. 정확도를 지표로 하면 매개변수의 미분이 대부분의 장소에서 0이 되기 때문이다.
    * 예를 들어 100장 가운데 35장을 맞춘 모델이 있다면 35%의 정확률을 가지게 되며, 매개변수의 조정에 따라 정확률은 흔들리거나 멈출 수 있다
    * 실제로는 맞추는 대상은 달라지지만 갯수에 따라 정확률이 결정나기 때문에 미세한 차이를 가질 수 없다 1 단위로 불연속적으로 정확률이 변하기 때문이다
    * 반면, 손실함수의 경우는 소수점 이하의 값으로 나오게 되어 연속적인 값으로 비교가 가능하다.
    * 여기서 손실함수의 선택이 중요한다 계단함수의 경우는 대부분의 위치에서 기울기가 0이지만, sigmoid 함수의 경우는 기울기가 0인 지점이 없다.

### Neural Network 구성하는 과정은 무엇을 의미하는가?
* 결국 *입력값과 출력값이 정해진 상태에서 임의의 방정식의 매개변수를 구하는 과정*이며 이러한 방정식은 다양한 방법으로 구할 수 있다
* 단순한 2차 방정식을 통해 2개의 해를 구할 수도 있겠지만, 차수를 높이거나(노드의 수를 늘리는 경우), 변수를 늘리거나(노드의 깊이를 늘리는 경우) 할 수도 있다
    * 즉, 이러한 *방정식의 해를 구하는 과정을 matrix 연산을 통해 가능하며, 이를 network 형태로 표현한 것*이 neural network 이다

### 각 Layer를 통과한다는 의미는 무엇인가?
* 방정식의 매개변수를 모르기 때문에, 임의의 매개변수(w,b)를 *대충 때려 맞추는 과정*이다.

### Activation Function 은 어떤 역할을 하는가?
* 어차피 때려 맞춘 값이므로, 똑같은 가중치에 선형적인 증가함수를 통과하는 것은 결과가 선형적이므로 같은 결과다 의미 없다
* 그래서 랜덤한 가중치와, 비선형적인 함수를 통해서 랜덤하게 값에 변화를 주는 것 *매개변수의 값을 흔드는 과정*이다
* 주어진 확률변수를 단조증가 함수인 sigmoid 함수의 결과로 변환하는 과정이며, 학습이 진행함에 따라 sigmoid 곡선 상의 임의의 점을 왔다갔다 한다는 의미다

### 1회 Forward 과정을 거치는 것은 어떤 의미인가?
* *처음으로 매개변수를 구한 과정*이며, 절대 정확하지 방정식을 구한 상태이다. (졸라 복잡한 방정식이다)

### Cost Funciton 은 어떤 역할을 하는가?
* *대충 때려잡은 방정식이 얼마나 정확한 지를 판단하는 과정*이며, 여기서 다양한 비용함수(MSE, CEE)를 통해 구할 수 있다 

### 왜 미분이라는 과정을 거치는가?
* 방정식을 구했고, 이 *방정식의 매개변수는 2개(w,b)이므로 최종 출력값(해)와의 차이(오차)를 최소화* 하기 위해 편미분을 한다


## 4.3 수치 미분

### 4.3.1 미분
* 속도 (거리/시간) = 단위 시간 당 달린 평균 거리를 말함
    * 단위 시간이 충분히 작은 시간인 경우(순간)의 변화량을 말함 (delta)
    * 미분(differentiation, derivative) = df(x)/dx = ( f(x+dx) - f(x) ) / dx
```python
    def numerical_diff(f, x):
        h = 10e-50
        return (f(x + h) - f(x)) / h
```
    * 여기서의 문제점은 부동소수점의 한계


## 4.4 기울기
* x0와 x1의 편미분ㅇ르 동시에 계산하여, (df/dx0, df/dx1)과 같이 모든 변수의 편미분을 벡터로 정리한 것을 기울기gradient라고 합니다.
```python
    def numerical_gradient(f, x):
        h = 1e-4
        grad = np.zeros_like(x)
        for idx in range(x.size):
            tmp_value = x[idx]
            x[idx] = tmp_val + h
            fxh1 = f(x)
            x[idx] = tmp_val - h
            fxh2 = f(x)
            grad[idx] = (fxh1 - fxh2) / (2*h)
            x[idx] = tmp_val
        return grad
```

### 4.4.1 경사하강법
* 최적의 매개변수 즉 손실 함수가 최솟값이될 때의 매개변수 값을 말하는데, 일반적인 손실함수의 공간은 광대하여 어디가 최솟값이 되는지 알기 어렵습니다.
    * 이런 상황에서 기울기를 잘 이용해 함수의 최솟값을 찾으려는 것이 경사법입니다
    * 함수가 극솟값(국소적인 최솟값), 최솟값, 또 안장점saddle point이 되는 장소에서는 기울기가 0입니다.
    * 경사법은 기울기가 0인 지점을 찾지만 그 장소가 반드시 최솟값이라 볼 수는 없으며, 경우에 따라 평평한 고원plateau, 플레토를 찾아 정체될 수 있습니다.
* 하이퍼파라미터hyper parameter, 초매개변수란?
    * 가중치, 편향과 같은 자동으로 획득되는 매개변수와 다르게, 사람이 직접 설정해야만 하는 매개변수를 말한다
    * 학습횟수, 학습비율 등을 말함


## 4.5 학습 알고리즘 구현하기
* 전제
* 1단계 - 미니배치
* 2단계 - 기울기 산출
* 3단계 - 매개변수 갱신
* 4단계 - 반복

### 4.5.3 시험 데이터로 평가하기
* 에폭epoch ?
    * 학습에서 훈련 데이터를 모두 소진했을 때의 횟수에 해당하며, 10,000개를 100개 미니배치로 100회 수행하면 이를 1에폭이라 한다.

